#é€šè¿‡KNNç®—æ³•å®ç° é¸¢å°¾èŠ±åˆ†ç±»
# æœºå™¨å­¦ä¹ é¡¹ç›®ç ”å‘çš„ä¸€èˆ¬æµç¨‹
# 1ï¼ŒåŠ è½½æ•°æ®
# 2ï¼Œæ•°æ®é¢„å¤„ç†
# 3ï¼Œç‰¹å¾å·¥ç¨‹
#     ç‰¹å¾æå–
#     é¢„å¤„ç†
#     ã€‚ã€‚ã€‚
# 4ï¼Œæ¨¡å‹è®­ç»ƒ
# 5ï¼Œæ¨¡å‹è¯„ä¼°
# 6ï¼Œæ¨¡å‹é¢„æµ‹

# å¯¼åŒ…
from sklearn.datasets import load_iris  #åŠ è½½é¸¢å°¾èŠ±æµ‹è¯•é›†
import seaborn as sns                   #
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split    #åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
from sklearn.preprocessing import StandardScaler        #æ•°æ®æ ‡å‡†åŒ–
from sklearn.neighbors import KNeighborsClassifier      #KNNç®—æ³•åˆ†ç±»å¯¹è±¡
from sklearn.metrics import accuracy_score              #æ¨¡å‹è¯„ä¼°

#1ï¼Œå®šä¹‰å‡½æ•°ï¼ŒåŠ è½½é¸¢å°¾èŠ±
def fun_load_iris():
    iris_data = load_iris()
    #print(f'æ•°æ®é›†:{iris_data}') #å­—å…¸ç±»å‹
    #print(f'æ•°æ®é›†çš„ç±»å‹:{type(iris_data)}')



    # æ•°æ®é›†ä¸­æ‰€æœ‰çš„é”®
    # dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])
    #data æ•°æ®
    #feature_names ç‰¹å¾å
    #target æ ‡ç­¾çš„key 0,1,2
    #target_names æ ‡ç­¾çš„value ['setosa' 'versicolor' 'virginica']

    # print('æ•°æ®é›†ä¸­æ‰€æœ‰çš„é”®',iris_data.keys())
    # print(f'å…·ä½“çš„æ•°æ®ï¼š\n{iris_data.data[0:5]}') #å–å‰5æ¡æ•°æ®ï¼Œæ€»å…±150æ¡æ•°æ®
    # print(f'ç‰¹å¾çš„åå­—ï¼š{iris_data.feature_names}')
    # print(f'èŠ±çš„ç±»å‹åkeyï¼š{iris_data.target[:5]}')
    # print(f'èŠ±çš„ç±»å‹åvalueï¼š{iris_data.target_names}')
    # print(f'æ•°æ®çš„æè¿°ä¿¡æ¯:\n{iris_data.DESCR}')
    # print(f'æ•°æ®é›†çš„æ¡†æ¶:{iris_data.frame}')

#2ï¼Œå®šä¹‰å‡½æ•°ï¼Œç»˜åˆ¶æ•°æ®é›†çš„æ•£ç‚¹å›¾
def fun_show_iris():
    #1ï¼ŒåŠ è½½æ•°æ®é›†
    iris_data = load_iris()

    #2ï¼ŒæŠŠæ•°æ®é›†å°è£…ä¸ºDataFrame
    iris_df = pd.DataFrame(data = iris_data.data, columns = iris_data.feature_names)

    #3,æ–°å¢ä¸€åˆ—->æ ‡ç­¾åˆ—
    iris_df['label'] = iris_data.target

    #4,é€šè¿‡Seanbornç»˜åˆ¶æ•£ç‚¹å›¾
    sns.lmplot(iris_df, x = 'sepal length (cm)', y = 'sepal width (cm)', hue = 'label', fit_reg = True )  #æ ¹æ®labelåˆ†ç»„

    #5,è®¾ç½®æ ‡é¢˜æ˜¾ç¤º
    plt.title('iris data') #è‡ªåŠ¨è°ƒæ•´å­å›¾å‚æ•°ï¼Œä»¥ä½¿æ•´ä¸ªç»™å›¾åƒçš„è¾¹ç•Œä¸å­å›¾åŒ¹é…
    plt.tight_layout()
    plt.show()
    print(iris_df)

#3ï¼Œå®šä¹‰å‡½æ•°ï¼Œåˆ‡åˆ†è®­ç»ƒé›†å’Œæ•°æ®é›†
def fun_split_train_test():
    #åŠ è½½æ•°æ®é›†
    iris_data = load_iris()

    #æ•°æ®çš„é¢„å¤„ç†ï¼Œä»150ä¸ªç‰¹å¾å’Œæ ‡ç­¾ä¸­ï¼ŒæŒ‰ç…§8ï¼š2çš„æ¯”ä¾‹åˆ‡åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
                    # å…ƒç»„ï¼ˆTupleï¼‰æ˜¯Pythonä¸­ä¸€ç§éå¸¸é‡è¦çš„æ•°æ®ç»“æ„ã€‚è®©æˆ‘ç”¨ç®€å•çš„è¯­è¨€è§£é‡Šï¼š
                    #
                    # ä»€ä¹ˆæ˜¯å…ƒç»„ï¼Ÿ
                    # å…ƒç»„æ˜¯ä¸€ä¸ªä¸å¯å˜çš„ã€æœ‰åºçš„å…ƒç´ é›†åˆã€‚
                    #
                    # åŸºæœ¬ç‰¹ç‚¹ï¼š
                    # ğŸ“ ä¸å¯å˜ï¼šåˆ›å»ºåä¸èƒ½ä¿®æ”¹ï¼ˆä¸èƒ½å¢ã€åˆ ã€æ”¹å…ƒç´ ï¼‰
                    #
                    # ğŸ”¢ æœ‰åºï¼šå…ƒç´ æœ‰å›ºå®šçš„é¡ºåº
                    #
                    # ğŸ“¦ å¯ä»¥å­˜å‚¨ä»»æ„ç±»å‹ï¼šæ•°å­—ã€å­—ç¬¦ä¸²ã€åˆ—è¡¨ç­‰éƒ½å¯ä»¥
                    # # æ–¹æ³•1ï¼šä½¿ç”¨åœ†æ‹¬å·
                    # tuple1 = (1, 2, 3, 4)
                    # tuple2 = ("è‹¹æœ", "é¦™è•‰", "æ©™å­")
                    #
                    # # æ–¹æ³•2ï¼šä¸ä½¿ç”¨æ‹¬å·ï¼ˆé€—å·åˆ†éš”ï¼‰
                    # tuple3 = 1, 2, 3  # è‡ªåŠ¨å˜æˆå…ƒç»„ (1, 2, 3)
                    #
                    # # æ–¹æ³•3ï¼šå•ä¸ªå…ƒç´ çš„å…ƒç»„ï¼ˆå¿…é¡»åŠ é€—å·ï¼‰
                    # single_tuple = (5,)  # è¿™æ˜¯å…ƒç»„
                    # not_tuple = (5)  # è¿™åªæ˜¯æ•°å­—5ï¼Œä¸æ˜¯å…ƒç»„ï¼
                    #
    x_train, x_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.2, random_state = 23)
    print(f'è®­ç»ƒé›†çš„ç‰¹å¾:{x_train}, ä¸ªæ•°ï¼š{len(x_train)}')
    print(f'è®­ç»ƒé›†çš„æ ‡ç­¾:{y_train}, ä¸ªæ•°ï¼š{len(y_train)}')
    print(f'æµ‹è¯•é›†çš„ç‰¹å¾:{x_test}, ä¸ªæ•°ï¼š{len(x_test)}')
    print(f'æµ‹è¯•é›†çš„æ ‡ç­¾:{y_test}, ä¸ªæ•°ï¼š{len(y_test)}')

#4ï¼Œå®šä¹‰å‡½æ•°ï¼Œå®ç°é¸¢å°¾èŠ±å®Œæ•´æ¡ˆä¾‹-> åŠ è½½æ•°æ®ï¼Œæ•°æ®é¢„å¤„ç†ï¼Œç‰¹å¾å·¥ç¨‹ï¼Œæ¨¡å‹è®­ç»ƒï¼Œæ¨¡å‹è¯„ä¼°ï¼Œæ¨¡å‹é¢„æµ‹
def fun_iris_evaluate_test():
    #1, åŠ è½½æ•°æ®é›†
    iris_data = load_iris()

    #2ï¼Œæ•°æ®é¢„å¤„ç†
    x_train, x_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.2, random_state = 22)

    #3,ç‰¹å¾å·¥ç¨‹(æå–ï¼Œé¢„å¤„ç†)
        #ç‰¹å¾æå–ï¼šå› ä¸ºæºæ•°æ®åªæœ‰å››ä¸ªç‰¹å¾åˆ—ï¼Œä¸”éƒ½æ˜¯æˆ‘ä»¬è¦ç”¨çš„ï¼Œæ‰€ä»¥æ— éœ€ç‰¹å¾æå–
        #ç‰¹å¾é¢„å¤„ç†:å› ä¸ºæºæ•°æ®çš„å››åˆ—ç‰¹å¾çš„æ’å€¼ä¸å¤§ï¼Œæ‰€ä»¥æˆ‘ä»¬æ— éœ€é¢„å¤„ç†ï¼Œä½†æ˜¯ä¸ºäº†ä»£ç å®Œæ•´ï¼Œæˆ‘ä»¬è¿›è¡Œé¢„å¤„ç†
        #æ ‡å‡†åŒ–
    scaler = StandardScaler()#æ ‡å‡†åŒ–å¯¹è±¡
    x_train = scaler.fit_transform(x_train)
    x_test = scaler.transform(x_test)

    #4,æ¨¡å‹è®­ç»ƒ
    estimator = KNeighborsClassifier(n_neighbors = 3)
    estimator.fit(x_train, y_train)

    #5,æ¨¡å‹é¢„æµ‹(åˆ‡åˆ†çš„æµ‹è¯•é›†)
    y_pred = estimator.predict(x_test)
    print(f"åˆ‡åˆ†é¢„æµ‹å€¼ä¸º:{y_pred}")

    #5,æ–°æ•°æ®çš„é¢„æµ‹
    my_data = [[7.8, 2.1, 3.9, 1.6]]
    my_data = scaler.transform(my_data)
    y_pred_new = estimator.predict(my_data)
    print(f"y_pred_new:{y_pred_new}")
    print(f"y_pred_new_score:{estimator.predict_proba(my_data)}")

    #6ï¼Œæ¨¡å‹è¯„ä¼°
        #æ–¹å¼1ï¼šç›´æ¥è¯„åˆ†ï¼ŒåŸºäºè®­ç»ƒé›†çš„ç‰¹å¾å’Œæ ‡ç­¾
    print(f'æ­£ç¡®ç‡(å‡†ç¡®ç‡)ï¼š{estimator.score(x_train, y_train)}')

        #æ–¹å¼2ï¼š
    print(f'å‡†ç¡®ç‡(æ­£ç¡®ç‡){accuracy_score(y_test, estimator.predict(x_test))}')





if __name__ == '__main__':
    # fun_load_iris()
    # fun_show_iris()
    fun_iris_evaluate_test()